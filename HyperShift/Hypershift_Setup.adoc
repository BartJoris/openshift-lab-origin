= HyperShift Setup

== Overview

This document describes how to install and configure Hypershift from scratch. It also explains how to deploy a managed cluster using Hypershift.

This document is not part of the lab (the environment has been pre-provisioned) but rather is provided as background information to explain what has been set up.

== Docs

* RHACM 2.5: https://access.redhat.com/documentation/en-us/red_hat_advanced_cluster_management_for_kubernetes/2.5/html/clusters/managing-your-clusters#hosted-control-plane-intro
* RHACM 2.6: https://access.redhat.com/documentation/en-us/red_hat_advanced_cluster_management_for_kubernetes/2.6/html/multicluster_engine/multicluster_engine_overview#hosted-control-planes-intro

== Prerequisites

. Deploy an OpenShift 4.11 cluster
. On that cluster install Advanced Cluster Manager (operator and operand)
. Get your AWS credentials ready
* AWS Access Key
* AWS Secret Access Key
* Top level domain (sandboxXXXX.opentlc.com)
. Retrieve your private and public key (e.g. ~/.ssh/${GUID}key.pem and ~/.ssh/${GUID}key.pub)
. Make sure you have your OpenShift Pull Secret in a file `$HOME/pullsecret.json`

. Set up AWS Credentials in file `~/.aws/credentials`
+
[source,texinfo]
----
[default]
aws_access_key_id = YOUR_AWS_ACCESS_KEY_ID
aws_secret_access_key = YOUR_AWS_SECRET_ACCESS_KEY
----

. Enable the HyperShift Preview Tech Preview:
+
[source,sh]
----
oc patch mce multiclusterengine -n multicluster-engine --type=merge -p '{"spec":{"overrides":{"components":[{"name":"hypershift-preview","enabled": true}]}}}'
----

. Deploy Hypershift. Create a file `managed_cluster.yaml`
+
[source,yaml]
----
---
apiVersion: cluster.open-cluster-management.io/v1
kind: ManagedCluster
metadata:
  labels:
    local-cluster: "true"
  name: local-cluster
spec:
  hubAcceptsClient: true
  leaseDurationSeconds: 60
----

. Create the managed cluster:
+
[source,sh]
----
oc apply -f managed_cluster.yaml
----

. Hypershift needs an AWS S3 Bucket to store OICD documents (although Minio or OpenShift Data Foundations should work as well).
+
. Create an AWS S3 Bucket:
+
[source,sh]
----
aws s3api create-bucket --bucket oidc-storage --region us-east-2 --create-bucket-configuration LocationConstraint=us-east-2
----

. Create a secret with AWS credential information in the `local-cluster` namespace:
+
[source,sh]
----
oc create secret generic hypershift-operator-oidc-provider-s3-credentials -n local-cluster --from-file=credentials=$HOME/.aws/credentials --from-literal=bucket=oidc-storage --from-literal=region=us-east-2

oc label secret hypershift-operator-oidc-provider-s3-credentials cluster.open-cluster-management.io/backup="" -n local-cluster
----

. Create the Managed Cluster Addon File `managedclusteraddon.yaml`:
+
[source,yaml]
----
---
apiVersion: addon.open-cluster-management.io/v1alpha1
kind: ManagedClusterAddOn
metadata:
  name: hypershift-addon
  namespace: local-cluster
spec:
  installNamespace: open-cluster-management-agent-addon
----

. Create the managed cluster addon:
+
[source,sh]
----
oc apply -f managedclusteraddon.yaml
----

Your Red Hat Advanced Cluster Management for Kubernetes is now configured for the Hypershift Tech Preview.

== Deploy a cluster using Hypershift

Now that Hypershift Tech Preview has been enabled in RHACM you can use it to deploy a new cluster.

. Create namespace to collect all Hypershift resources:
+
[source,sh]
----
oc create namespace hypershift
----

. Hypershift needs some information available in a secret. This information includes:

* Top level Domain for provisioned clusters
* AWS Access Key ID
* AWS Secret ACCESS Key
* Your Pull Secret to allow the pull of OpenShift Container Platform images
* A private and public key
+
Create the AWS Credentials Secret for Hypershift:
+
[source,sh]
----
oc create secret generic aws-credentials -n hypershift \
   --from-literal=baseDomain='sandboxXXXX.opentlc.com' \
   --from-literal=aws_access_key_id='YOUR_ACCESS_KEY_ID' \
   --from-literal=aws_secret_access_key='YOUR_SECRET_ACCESS_KEY' \
   --from-file=pullSecret=~/.pullsecret.json \
   --from-file=ssh-publickey=~/.ssh/wkacmkey.pub \
   --from-file=ssh-privatekey=~/.ssh/wkacmkey.pem

oc label secret aws-credentials -n hypershift cluster.open-cluster-management.io/backup=""
----

. Create a YAML file `development.yaml` with cluster properties:
+
[source,yaml]
----
---
apiVersion: cluster.open-cluster-management.io/v1alpha1
kind: HypershiftDeployment
metadata:
  name: development
  namespace: hypershift
spec:
  hostingCluster: local-cluster
  hostingNamespace: clusters
  hostedClusterSpec:
    networking:
      machineCIDR: 10.0.0.0/16    # Default
      networkType: OpenShiftSDN
      podCIDR: 10.132.0.0/14      # Default
      serviceCIDR: 172.31.0.0/16  # Default
    platform:
      type: AWS
    pullSecret:
      name: development-pull-secret    # This secret is created by the controller
    release:
      image: quay.io/openshift-release-dev/ocp-release:4.11.8-x86_64
    services:
    - service: APIServer
      servicePublishingStrategy:
        type: LoadBalancer
    - service: OAuthServer
      servicePublishingStrategy:
        type: Route
    - service: Konnectivity
      servicePublishingStrategy:
        type: Route
    - service: Ignition
      servicePublishingStrategy:
        type: Route
    sshKey: {}
  nodePools:
  - name: development
    spec:
      clusterName: development
      management:
        autoRepair: false
        replace:
          rollingUpdate:
            maxSurge: 1
            maxUnavailable: 0
          strategy: RollingUpdate
        upgradeType: Replace
      platform:
        aws:
          instanceType: m5.large
        type: AWS
      release:
        image: quay.io/openshift-release-dev/ocp-release:4.11.8-x86_64
      replicas: 2
  infrastructure:
    cloudProvider:
      name: aws-credentials # The secret you previously created
    configure: True
    platform:
      aws:
        region: us-west-2
----

. Deploy the cluster:
+
[source,sh]
----
oc apply -f development.yaml
----

* Wait until the cluster shows deployed:
+
[source,sh]
----
watch -n 10 oc get hypershiftdeployment -n hypershift
----
+
.Sample Output
[source,texinfo,options=nowrap]
----
NAME	  TYPE   INFRA                  IAM                    MANIFESTWORK           PROVIDER REF   PROGRESS    AVAILABLE
development    AWS    ConfiguredAsExpected   ConfiguredAsExpected   ConfiguredAsExpected   AsExpected     Completed   True
----

== Access cluster(s)

The kubeadmin password and kubeconfig file are stored in secrets in the `local-cluster`namespace.

* `<clustername>-kubeadmin-password`
* `<clustername>-admin-kubeconfig`

. Get the kubeadmin password:
+
[source,sh]
----
oc get secret development-kubeadmin-password -n local-cluster --template='{{ .data.password }}' | base64 -d ; echo
----

. Get the kubeconfig file and save it as `$HOME/kubeconfig-<clustername>.yaml`
+
[source,sh]
----
oc get secret development-admin-kubeconfig -n local-cluster --template='{{ .data.kubeconfig }}' | base64 -d >$HOME/kubeconfig-development.yaml
----

. Set the KUBECONFIG variable to point to the new kube config file
+
[source,sh]
----
export KUBECONFIG=$HOME/kubeconfig-development.yaml
----

. Validate the configuration
+
[source,sh]
----
oc get co
----

. Get the console URL
+
[source,sh]
----
oc whoami --show-console
----

. Log into the console using `kubeadmin` and the previously retrieved kubeadmin password.

. Unset the KUBECONFIG variable to work back on your local cluster.
+
[source,sh]
----
unset KUBECONFIG
----
