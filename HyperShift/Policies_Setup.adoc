= Policies for Hypershift cluster

Every deployed cluster needs some configuration done. While the authentication can be setup via the `HostedCluster` resource it takes policies to deploy authorization and additional operators to the cluster.

In this document we set up:

* Authorization (cluster-admin for the `admin` user)
* Pipelines Operator
* OpenShift Gitops Operator
* Serverless Operator

== Prerequisites

Right now we are creating these policies as YAML resources on the bastion VM. These can/will be converted into a GitOps repository at a later point in time.

. Create a directory to hold the policy files:
+
[source,sh]
----
mkdir ${HOME}/policies
----

. Create a namespace to hold all the policies:
+
[source,sh]
----
cat << EOF >$HOME/policies/namespace.yaml
---
apiVersion: v1
kind: Namespace
metadata:
  name: rhdp-policies
EOF
----

. Create the namespace:
+
[source,sh]
----
oc apply -f $HOME/policies/namespace.yaml
----

== Set up authorization

The htpasswd authentication that has been set up during cluster deployment includes a user named `admin`. This user should have cluster admin privileges because when authentication is deployed during cluster deploy no `kubeadmin` user gets created - and therefore it would be impossible to log into the OpenShift console with administrative privileges.

The clusters are all labeled with `type: sandbox` - which is the selector that we will use to deploy the policies.

. Create a directory to hold the files:
+
[source,sh]
----
mkdir -p ${HOME}/policies/authorization
----

. Create a policy to create a ClusterRoleBinding:
+
[source,sh]
----
cat << EOF >$HOME/policies/authorization/policy.yaml
---
apiVersion: policy.open-cluster-management.io/v1
kind: Policy
metadata:
  name: admin-authorization
  namespace: rhdp-policies
spec:
  remediationAction: enforce
  disabled: false
  policy-templates:
  - objectDefinition:
      apiVersion: policy.open-cluster-management.io/v1
      kind: ConfigurationPolicy
      metadata:
        name: admin-authorization
      spec:
        remediationAction: enforce
        pruneObjectBehavior: DeleteIfCreated
        severity: medium
        object-templates:
        - complianceType: musthave
          objectDefinition:
            apiVersion: rbac.authorization.k8s.io/v1
            kind: ClusterRoleBinding
            metadata:
              annotations:
                rbac.authorization.kubernetes.io/autoupdate: "true"
              name: admin-authorization
            roleRef:
              apiGroup: rbac.authorization.k8s.io
              kind: ClusterRole
              name: cluster-admin
            subjects:
            - apiGroup: rbac.authorization.k8s.io
              kind: User
              name: admin
EOF
----

. Create a Placement Rule:
+
[source,sh]
----
cat << EOF >$HOME/policies/authorization/placementrule.yaml
---
apiVersion: apps.open-cluster-management.io/v1
kind: PlacementRule
metadata:
  name: admin-authorization
  namespace: rhdp-policies
spec:
  clusterSelector:
    matchLabels:
      vendor: OpenShift
      type: sandbox
EOF
----

. Create a Placement Binding:
+
[source,sh]
----
cat << EOF >$HOME/policies/authorization/placementbinding.yaml
---
apiVersion: policy.open-cluster-management.io/v1
kind: PlacementBinding
metadata:
  name: admin-authorization
  namespace: rhdp-policies
placementRef:
  apiGroup: apps.open-cluster-management.io
  kind: PlacementRule
  name: admin-authorization
subjects:
- apiGroup: policy.open-cluster-management.io
  kind: Policy
  name: admin-authorization
EOF
----

. Create a kustomization file:
+
[source,sh]
----
cat << EOF >$HOME/policies/authorization/kustomization.yaml
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

resources:
- policy.yaml
- placementrule.yaml
- placementbinding.yaml
EOF
----

. Apply the policy to the hub cluster:
+
[source,sh]
----
oc apply -k $HOME/policies/authorization
----

== Install the OpenShift Pipelines operator

The clusters are all labeled with `type: sandbox` - which is the selector that we will use to deploy the policies.

. Create a directory to hold the files:
+
[source,sh]
----
mkdir -p ${HOME}/policies/pipelines
----

. Create a policy to create the OpenShift Pipelines Operator subscription:
+
[source,sh]
----
cat << EOF >$HOME/policies/pipelines/policy.yaml
---
apiVersion: policy.open-cluster-management.io/v1
kind: Policy
metadata:
  name: openshift-pipelines-installed
  namespace: rhdp-policies
spec:
  remediationAction: enforce
  disabled: false
  policy-templates:
  - objectDefinition:
      apiVersion: policy.open-cluster-management.io/v1
      kind: ConfigurationPolicy
      metadata:
        name: openshift-pipelines-installed
      spec:
        remediationAction: enforce
        pruneObjectBehavior: DeleteIfCreated
        severity: medium
        object-templates:
        - complianceType: musthave
          objectDefinition:
            apiVersion: operators.coreos.com/v1alpha1
            kind: Subscription
            metadata:
              name: openshift-pipelines
              namespace: openshift-operators
            spec:
              channel: pipelines-1.8
              installPlanApproval: Automatic
              name: openshift-pipelines-operator-rh
              source: redhat-operators
              sourceNamespace: openshift-marketplace
EOF
----

. Create a Placement Rule:
+
[source,sh]
----
cat << EOF >$HOME/policies/pipelines/placementrule.yaml
---
apiVersion: apps.open-cluster-management.io/v1
kind: PlacementRule
metadata:
  name: openshift-pipelines-installed
  namespace: rhdp-policies
spec:
  clusterSelector:
    matchLabels:
      vendor: OpenShift
      type: sandbox
EOF
----

. Create a Placement Binding:
+
[source,sh]
----
cat << EOF >$HOME/policies/pipelines/placementbinding.yaml
---
apiVersion: policy.open-cluster-management.io/v1
kind: PlacementBinding
metadata:
  name: openshift-pipelines-installed
  namespace: rhdp-policies
placementRef:
  apiGroup: apps.open-cluster-management.io
  kind: PlacementRule
  name: openshift-pipelines-installed
subjects:
- apiGroup: policy.open-cluster-management.io
  kind: Policy
  name: openshift-pipelines-installed
EOF
----

. Create a kustomization file:
+
[source,sh]
----
cat << EOF >$HOME/policies/pipelines/kustomization.yaml
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

resources:
- policy.yaml
- placementrule.yaml
- placementbinding.yaml
EOF
----

. Apply the policy to the hub cluster:
+
[source,sh]
----
oc apply -k $HOME/policies/pipelines
----

== Install the OpenShift GitOps operator

The clusters are all labeled with `type: sandbox` - which is the selector that we will use to deploy the policies.

. Create a directory to hold the files:
+
[source,sh]
----
mkdir -p ${HOME}/policies/gitops
----

. Create a policy to create the OpenShift gitops Operator subscription:
+
[source,sh]
----
cat << EOF >$HOME/policies/gitops/policy.yaml
---
apiVersion: policy.open-cluster-management.io/v1
kind: Policy
metadata:
  name: openshift-gitops-installed
  namespace: rhdp-policies
spec:
  remediationAction: enforce
  disabled: false
  policy-templates:
  - objectDefinition:
      apiVersion: policy.open-cluster-management.io/v1
      kind: ConfigurationPolicy
      metadata:
        name: openshift-gitops-installed
      spec:
        remediationAction: enforce
        pruneObjectBehavior: DeleteIfCreated
        severity: medium
        object-templates:
        - complianceType: musthave
          objectDefinition:
            apiVersion: operators.coreos.com/v1alpha1
            kind: Subscription
            metadata:
              name: openshift-gitops-operator
              namespace: openshift-operators
            spec:
              channel: stable
              installPlanApproval: Automatic
              name: openshift-gitops-operator
              source: redhat-operators
              sourceNamespace: openshift-marketplace
EOF
----

. Create a Placement Rule:
+
[source,sh]
----
cat << EOF >$HOME/policies/gitops/placementrule.yaml
---
apiVersion: apps.open-cluster-management.io/v1
kind: PlacementRule
metadata:
  name: openshift-gitops-installed
  namespace: rhdp-policies
spec:
  clusterSelector:
    matchLabels:
      vendor: OpenShift
      type: sandbox
EOF
----

. Create a Placement Binding:
+
[source,sh]
----
cat << EOF >$HOME/policies/gitops/placementbinding.yaml
---
apiVersion: policy.open-cluster-management.io/v1
kind: PlacementBinding
metadata:
  name: openshift-gitops-installed
  namespace: rhdp-policies
placementRef:
  apiGroup: apps.open-cluster-management.io
  kind: PlacementRule
  name: openshift-gitops-installed
subjects:
- apiGroup: policy.open-cluster-management.io
  kind: Policy
  name: openshift-gitops-installed
EOF
----

. Create a kustomization file:
+
[source,sh]
----
cat << EOF >$HOME/policies/gitops/kustomization.yaml
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

resources:
- policy.yaml
- placementrule.yaml
- placementbinding.yaml
EOF
----

. Apply the policy to the hub cluster:
+
[source,sh]
----
oc apply -k $HOME/policies/gitops
----

== Install the OpenShift Serverless operator

The clusters are all labeled with `type: sandbox` - which is the selector that we will use to deploy the policies.

. Create a directory to hold the files:
+
[source,sh]
----
mkdir -p ${HOME}/policies/serverless
----

. Create a policy to create the OpenShift serverless Operator subscription:
+
[source,sh]
----
cat << EOF >$HOME/policies/serverless/policy.yaml
---
apiVersion: policy.open-cluster-management.io/v1
kind: Policy
metadata:
  name: openshift-serverless-installed
  namespace: rhdp-policies
spec:
  remediationAction: enforce
  disabled: false
  policy-templates:
  - objectDefinition:
      apiVersion: policy.open-cluster-management.io/v1
      kind: ConfigurationPolicy
      metadata:
        name: openshift-serverless-installed
      spec:
        remediationAction: enforce
        pruneObjectBehavior: DeleteIfCreated
        severity: medium
        object-templates:
        - complianceType: musthave
          objectDefinition:
            apiVersion: operators.coreos.com/v1alpha1
            kind: Subscription
            metadata:
              name: openshift-serverless-operator
              namespace: openshift-operators
            spec:
              channel: stable
              installPlanApproval: Automatic
              name: serverless-operator
              source: redhat-operators
              sourceNamespace: openshift-marketplace
        - complianceType: musthave
          objectDefinition:
            apiVersion: v1
            kind: Namespace
            metadata:
              name: knative-serving
        - complianceType: musthave
          objectDefinition:
            apiVersion: v1
            kind: Namespace
            metadata:
              name: knative-eventing
        - complianceType: musthave
          objectDefinition:
            apiVersion: operator.knative.dev/v1alpha1
            kind: KnativeServing
            metadata:
              name: knative-serving
              namespace: knative-serving
        - complianceType: musthave
          objectDefinition:
            apiVersion: operator.knative.dev/v1alpha1
            kind: KnativeEventing
            metadata:
              name: knative-eventing
              namespace: knative-eventing
EOF
----

. Create a Placement Rule:
+
[source,sh]
----
cat << EOF >$HOME/policies/serverless/placementrule.yaml
---
apiVersion: apps.open-cluster-management.io/v1
kind: PlacementRule
metadata:
  name: openshift-serverless-installed
  namespace: rhdp-policies
spec:
  clusterSelector:
    matchLabels:
      vendor: OpenShift
      type: sandbox
EOF
----

. Create a Placement Binding:
+
[source,sh]
----
cat << EOF >$HOME/policies/serverless/placementbinding.yaml
---
apiVersion: policy.open-cluster-management.io/v1
kind: PlacementBinding
metadata:
  name: openshift-serverless-installed
  namespace: rhdp-policies
placementRef:
  apiGroup: apps.open-cluster-management.io
  kind: PlacementRule
  name: openshift-serverless-installed
subjects:
- apiGroup: policy.open-cluster-management.io
  kind: Policy
  name: openshift-serverless-installed
EOF
----

. Create a kustomization file:
+
[source,sh]
----
cat << EOF >$HOME/policies/serverless/kustomization.yaml
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

resources:
- policy.yaml
- placementrule.yaml
- placementbinding.yaml
EOF
----

. Apply the policy to the hub cluster:
+
[source,sh]
----
oc apply -k $HOME/policies/serverless
----

= Remove kubeadmin user

When using the `hypershift` CLI to deploy a cluster authentication can only be added after the cluster has been created. Therefore a `kubeadmin` user exists on the cluster. Use the following policy to remove the `kubeadmin` user from all managed clusters.

. Create a directory to hold the files:
+
[source,sh]
----
mkdir -p ${HOME}/policies/kubeadmin-absent
----

. Create a policy to create the OpenShift kubeadmin-absent Operator subscription:
+
[source,sh]
----
cat << EOF >$HOME/policies/kubeadmin-absent/policy.yaml
---
apiVersion: policy.open-cluster-management.io/v1
kind: Policy
metadata:
  name: kubeadmin-absent
  namespace: rhdp-policies
spec:
  remediationAction: enforce
  disabled: false
  policy-templates:
  - objectDefinition:
      apiVersion: policy.open-cluster-management.io/v1
      kind: ConfigurationPolicy
      metadata:
        name: kubeadmin-absent
      spec:
        remediationAction: enforce
        severity: medium
        object-templates:
        - complianceType: mustnothave
          objectDefinition:
            apiVersion: v1
            kind: Secret
            metadata:
              name: kubeadmin
              namespace: kube-system
EOF
----

. Create a Placement Rule:
+
[source,sh]
----
cat << EOF >$HOME/policies/kubeadmin-absent/placementrule.yaml
---
apiVersion: apps.open-cluster-management.io/v1
kind: PlacementRule
metadata:
  name: kubeadmin-absent
  namespace: rhdp-policies
spec:
  clusterSelector:
    matchLabels:
      vendor: OpenShift
      type: sandbox
EOF
----

. Create a Placement Binding:
+
[source,sh]
----
cat << EOF >$HOME/policies/kubeadmin-absent/placementbinding.yaml
---
apiVersion: policy.open-cluster-management.io/v1
kind: PlacementBinding
metadata:
  name: kubeadmin-absent
  namespace: rhdp-policies
placementRef:
  apiGroup: apps.open-cluster-management.io
  kind: PlacementRule
  name: kubeadmin-absent
subjects:
- apiGroup: policy.open-cluster-management.io
  kind: Policy
  name: kubeadmin-absent
EOF
----

. Create a kustomization file:
+
[source,sh]
----
cat << EOF >$HOME/policies/kubeadmin-absent/kustomization.yaml
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

resources:
- policy.yaml
- placementrule.yaml
- placementbinding.yaml
EOF
----

. Apply the policy to the hub cluster:
+
[source,sh]
----
oc apply -k $HOME/policies/kubeadmin-absent
----

== Cert Manager

Create application to install cert manager (1.10.2, 1.11.0 does not work)

.Namespace
[source,sh]
----
---
apiVersion: v1
kind: Namespace
metadata:
  name: cert-manager
  annotations:
    openshift.io/display-name: Cert Manager
----

.Channel
[source,sh]
----
---
apiVersion: apps.open-cluster-management.io/v1
kind: Channel
metadata:
  annotations:
    apps.open-cluster-management.io/reconcile-rate: medium
  name: jetstack
  namespace: cert-manager
spec:
  pathname: https://charts.jetstack.io
  type: HelmRepo
----

.Subscription
[source,sh]
----
---
apiVersion: apps.open-cluster-management.io/v1
kind: Subscription
metadata:
  annotations:
  labels:
    app: cert-manager
  name: cert-manager
  namespace: cert-manager
spec:
  channel: cert-manager/jetstack
  name: cert-manager
  packageOverrides:
  - packageName: cert-manager
    packageAlias: cert-manager
    packageOverrides:
    - path: spec
      value:
        installCRDs: true
        extraArgs: ['--dns01-recursive-nameservers=1.1.1.1:53','--dns01-recursive-nameservers-only']
  packageFilter:
    version: "v1.10.2"
  placement:
    placementRef:
      kind: PlacementRule
      name: cert-manager
----

.PlacementRule
[source,sh]
----
---
apiVersion: apps.open-cluster-management.io/v1
kind: PlacementRule
metadata:
  name: cert-manager
  namespace: cert-manager
spec:
  clusterSelector:
    matchLabels:
      vendor: OpenShift
      type: sandbox
----

.Application
[source,sh]
----
---
apiVersion: app.k8s.io/v1beta1
kind: Application
metadata:
  name: cert-manager
  namespace: cert-manager
spec:
  componentKinds:
  - group: apps.open-cluster-management.io
    kind: Subscription
  descriptor: {}
  selector:
    matchLabels:
      app: cert-manager
----

.kustomization
[source,sh]
----
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

resources:
- namespace.yaml
- channel.yaml
- subscription.yaml
- application.yaml
- placementrule.yaml
----

=== AWS Secret Access Key

Find the Route53 Access Key that got provisioned (e.g. in ~/ec2-user/.aws/credentials).


*Manually* create AWS Secret Access Key secret:
+
[source,sh]
----
oc create secret generic aws-secret-access-key -n rhdp-policies \
  --from-literal=secret-access-key=XXXXXXXXX
----

. Create a directory to hold the files:
+
[source,sh]
----
mkdir -p ${HOME}/policies/aws-secret-access-key
----

. Create a policy to deploy the secret to the cert-manager directory
+
[source,sh]
----
cat << EOF >$HOME/policies/aws-secret-access-key/policy.yaml
---
apiVersion: policy.open-cluster-management.io/v1
kind: Policy
metadata:
  name: aws-secret-access-key
  namespace: rhdp-policies
spec:
  remediationAction: enforce
  disabled: false
  policy-templates:
  - objectDefinition:
      apiVersion: policy.open-cluster-management.io/v1
      kind: ConfigurationPolicy
      metadata:
        name: aws-secret-access-key
      spec:
        remediationAction: enforce
        severity: medium
        object-templates:
        - complianceType: musthave
          objectDefinition:
            apiVersion: v1
            kind: Secret
            metadata:
              name: aws-secret-access-key
              namespace: cert-manager
            data:
              secret-access-key: |
                {{hub fromSecret "rhdp-policies" "aws-secret-access-key" "secret-access-key" hub}}
EOF
----

. Create a Placement Rule:
+
[source,sh]
----
cat << EOF >$HOME/policies/aws-secret-access-key/placementrule.yaml
---
apiVersion: apps.open-cluster-management.io/v1
kind: PlacementRule
metadata:
  name: aws-secret-access-key
  namespace: rhdp-policies
spec:
  clusterSelector:
    matchLabels:
      vendor: OpenShift
      type: sandbox
EOF
----

. Create a Placement Binding:
+
[source,sh]
----
cat << EOF >$HOME/policies/aws-secret-access-key/placementbinding.yaml
---
apiVersion: policy.open-cluster-management.io/v1
kind: PlacementBinding
metadata:
  name: aws-secret-access-key
  namespace: rhdp-policies
placementRef:
  apiGroup: apps.open-cluster-management.io
  kind: PlacementRule
  name: aws-secret-access-key
subjects:
- apiGroup: policy.open-cluster-management.io
  kind: Policy
  name: aws-secret-access-key
EOF
----

. Create a kustomization file:
+
[source,sh]
----
cat << EOF >$HOME/policies/aws-secret-access-key/kustomization.yaml
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

resources:
- policy.yaml
- placementrule.yaml
- placementbinding.yaml
EOF
----

. Apply the policy to the hub cluster:
+
[source,sh]
----
oc apply -k $HOME/policies/aws-secret-access-key
----

In the workload create the resources to request certificates on any given cluster:

.ClusterIssuer
[source,sh]
----
---
apiVersion: cert-manager.io/v1
kind: ClusterIssuer
metadata:
  name: letsencrypt-production-route53
spec:
  acme:
    email: rhpds-admins@redhat.com
    server: https://acme-v02.api.letsencrypt.org/directory
    privateKeySecretRef:
      # Secret resource that will be used to store the account's private key.
      name: cluster-issuer-le-production
    solvers:
    - selector:
        dnsZones:
        - dev.redhatworkshops.io
      dns01:
        route53:
          region: us-east-2
          hostedZoneID: Z05529733R8M94YGRSMD8
          accessKeyID: AKIAR2AI7M4QV3KHWS2M
          secretAccessKeySecretRef:
            name: aws-secret-access-key
            key: secret-access-key
----

.Certificate
[source,sh]
----
---
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: ingress-cert
  namespace: openshift-ingress
spec:
  # Name of the secret to hold the issued certificate
  secretName: ingress-cert
  duration: 2160h # 90d
  renewBefore: 360h # 15d
  usages:
  - server auth
  - client auth
  dnsNames:
  - *.apps.hcp-wkh1.dev.redhatworkshops.io
  issuerRef:
    kind: ClusterIssuer
    name: letsencrypt-production-route53
    group: cert-manager.io
----

.IngressController
[source,sh]
----
---
apiVersion: operator.openshift.io/v1
kind: IngressController
metadata:
  name: default
  namespace: openshift-ingress-operator
spec:
  defaultCertificate:
    name: ingress-cert
----

-> Policy
[source,sh]
----
---
apiVersion: policy.open-cluster-management.io/v1
kind: Policy
metadata:
  name: cert-wkh1
  namespace: rhdp-policies
spec:
  remediationAction: enforce
  disabled: false
  policy-templates:
  - objectDefinition:
      apiVersion: policy.open-cluster-management.io/v1
      kind: ConfigurationPolicy
      metadata:
        name: cert-wkh1
      spec:
        remediationAction: enforce
        severity: medium
        object-templates:
        - complianceType: musthave
          objectDefinition:
            apiVersion: cert-manager.io/v1
            kind: ClusterIssuer
            metadata:
              name: letsencrypt-production-route53
            spec:
              acme:
                email: rhpds-admins@redhat.com
                server: https://acme-v02.api.letsencrypt.org/directory
                privateKeySecretRef:
                  # Secret resource that will be used to store the account's private key.
                  name: cluster-issuer-le-production
                solvers:
                - selector:
                    dnsZones:
                    - dev.redhatworkshops.io
                  dns01:
                    route53:
                      region: us-east-2
                      hostedZoneID: Z05529733R8M94YGRSMD8
                      accessKeyID: AKIAR2AI7M4QZEI5PSG2
                      secretAccessKeySecretRef:
                        name: aws-secret-access-key
                        key: secret-access-key
        - complianceType: musthave
          objectDefinition:
            apiVersion: cert-manager.io/v1
            kind: Certificate
            metadata:
              name: ingress-cert
              namespace: openshift-ingress
            spec:
              # Name of the secret to hold the issued certificate
              secretName: ingress-cert
              duration: 2160h # 90d
              renewBefore: 360h # 15d
              usages:
              - server auth
              - client auth
              dnsNames:
              - "*.apps.hcp-wkh1.dev.redhatworkshops.io"
              issuerRef:
                kind: ClusterIssuer
                name: letsencrypt-production-route53
                group: cert-manager.io
        - complianceType: musthave
          objectDefinition:
            apiVersion: operator.openshift.io/v1
            kind: IngressController
            metadata:
              name: default
              namespace: openshift-ingress-operator
            spec:
              defaultCertificate:
                name: ingress-cert
----
